<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tomas Beuzen</title>
    <link>https://www.tomasbeuzen.com/author/tomas-beuzen/</link>
      <atom:link href="https://www.tomasbeuzen.com/author/tomas-beuzen/index.xml" rel="self" type="application/rss+xml" />
    <description>Tomas Beuzen</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 10 Sep 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://www.tomasbeuzen.com/images/icon_hu711dd623cc2810410109350012a588da_14433_512x512_fill_lanczos_center_2.png</url>
      <title>Tomas Beuzen</title>
      <link>https://www.tomasbeuzen.com/author/tomas-beuzen/</link>
    </image>
    
    <item>
      <title>Multivariate Normal Distributions</title>
      <link>https://www.tomasbeuzen.com/post/multivariate-normal/</link>
      <pubDate>Thu, 10 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://www.tomasbeuzen.com/post/multivariate-normal/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Multivariate distribution are used when there is correlation between your variables: i.e., the value of one variable affects the value of the other(s). I always found multivariate distributions a difficult concept to understand. One of the simplest multivariate distributions is the multivariate normal distribution, the focus of this short post. The multivariate normal distribution really clicked for me when a friend gave me a very intuitive analogy which I&amp;rsquo;ll be using throughout this post.&lt;/p&gt;
&lt;p&gt;Imagine you want to measure two variables: your heart rate at 9:00am, and your heart rate at 9:05am in beats per minute (bpm). There is likely correlation between these two variables, i.e., your heart rate at 9:05am is probably pretty similar to your heart rate at 9:00am. You measure this data for 7 days, and you get the following data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import pandas as pd
import plotly.graph_objects as go
from scipy.stats import norm, multivariate_normal
np.random.seed(2020)
pd.options.plotting.backend = &amp;quot;plotly&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = pd.DataFrame({&amp;quot;9:00&amp;quot;: [60, 70, 45, 55, 61, 57, 64],
                   &amp;quot;9:05&amp;quot;: [62, 69, 45, 60, 62, 60, 67]})
df
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;9:00&lt;/th&gt;
      &lt;th&gt;9:05&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;60&lt;/td&gt;
      &lt;td&gt;62&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;70&lt;/td&gt;
      &lt;td&gt;69&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;45&lt;/td&gt;
      &lt;td&gt;45&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;55&lt;/td&gt;
      &lt;td&gt;60&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;61&lt;/td&gt;
      &lt;td&gt;62&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;57&lt;/td&gt;
      &lt;td&gt;60&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;67&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;While we&amp;rsquo;re here let&amp;rsquo;s check the correlation in our data (we&amp;rsquo;ll use this later on):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.corr()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;9:00&lt;/th&gt;
      &lt;th&gt;9:05&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;9:00&lt;/th&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
      &lt;td&gt;0.965826&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9:05&lt;/th&gt;
      &lt;td&gt;0.965826&lt;/td&gt;
      &lt;td&gt;1.000000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;There&amp;rsquo;s a strong positive correlation here, indicating that the two variables do appear to be related. In the next few sections, I&amp;rsquo;ll use the above data to build up to an intuition of the multivariate normal distribution.&lt;/p&gt;
&lt;h2 id=&#34;univariate-normal-distribution&#34;&gt;Univariate Normal Distribution&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s start by exploring the univariate (one variable) normal distribution. One thing you could do with the data above is model each variable as two independent univariate normal distributions, which are each defined by two parameters: the mean $\mu$ and the standard deviation $\sigma$. Let&amp;rsquo;s fit the two distributions now:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;mu_900, std_900 = norm.fit(df[&#39;9:00&#39;])
mu_905, std_905 = norm.fit(df[&#39;9:05&#39;])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have two univariate distributions, let&amp;rsquo;s randomly draw 7 observations from them to simulate a week of new data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.DataFrame({&amp;quot;9:00&amp;quot;: norm.rvs(mu_900, std_900, size=7).astype(int),
              &amp;quot;9:05&amp;quot;: norm.rvs(mu_905, std_905, size=7).astype(int)})
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;9:00&lt;/th&gt;
      &lt;th&gt;9:05&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;46&lt;/td&gt;
      &lt;td&gt;61&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;63&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;56&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;54&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;52&lt;/td&gt;
      &lt;td&gt;70&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;49&lt;/td&gt;
      &lt;td&gt;69&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;58&lt;/td&gt;
      &lt;td&gt;52&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;Notice anything strange? The heart rate measured at 9:00am is sometimes very different to the heart rate at 9:05am. By simulating our two variables as univariate normal distributions, there is no &amp;ldquo;sharing of information&amp;rdquo; between the variables, i.e., they are independent and don&amp;rsquo;t influence each other (although they probably should). Here are the two distributions for your reference:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x = np.linspace(40, 80, 100)
df_uvn = pd.DataFrame({&amp;quot;9:00&amp;quot;: norm.pdf(x, mu_900, std_900),
                       &amp;quot;9:05&amp;quot;: norm.pdf(x, mu_905, std_905)})
fig = df_uvn.plot(width=700, height=400, title=&amp;quot;Univariate Normal Heart Rate Distributions&amp;quot;)
fig.update_xaxes(title_text=&#39;Heart Rate&#39;)
fig.update_yaxes(title_text=&#39;Probability Density&#39;)
fig.update_layout(xaxis = dict(range=[0, 100], tickmode = &#39;linear&#39;, dtick = 20),
                  yaxis = dict(range=[0, 0.06], tickmode = &#39;linear&#39;, dtick = 0.01))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;

&lt;script src=&#34;https://cdn.plot.ly/plotly-latest.min.js&#34;&gt;&lt;/script&gt;



&lt;div id=&#34;plotly_graph_1.json&#34; class=&#34;plotly&#34; style=&#34;height:400px&#34;&gt;&lt;/div&gt;
&lt;script&gt;
    Plotly.d3.json(&#34;plotly_graph_1.json&#34;, function (err, fig) {
        Plotly.plot(&#39;plotly_graph_1.json&#39;, fig.data, fig.layout, { responsive: true });
    });
&lt;/script&gt;&lt;/p&gt;
&lt;h2 id=&#34;multivariate-normal-distribution&#34;&gt;Multivariate Normal Distribution&lt;/h2&gt;
&lt;p&gt;We could more realistically model our heart rate data as a multivariate distribution, which will include the correlation between the variables we noticed earlier. I&amp;rsquo;m going to let &lt;code&gt;scipy&lt;/code&gt; formulate the multivariate normal distribution for me and I&amp;rsquo;ll directly draw 7 observations from it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pd.DataFrame(multivariate_normal.rvs(df.mean(), df.cov(), size=7).astype(int),
             columns=[&amp;quot;9:00&amp;quot;, &amp;quot;9:05&amp;quot;])
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;9:00&lt;/th&gt;
      &lt;th&gt;9:05&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;57&lt;/td&gt;
      &lt;td&gt;56&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;62&lt;/td&gt;
      &lt;td&gt;62&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;55&lt;/td&gt;
      &lt;td&gt;57&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;44&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;60&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;60&lt;/td&gt;
      &lt;td&gt;60&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;71&lt;/td&gt;
      &lt;td&gt;70&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;Ah, much better, our simulated data is much closer to reality now than what we had previously with our univariate distributions. It&amp;rsquo;s a bit harder to plot this as we are now working in 3D (two dimensions for the variables, one for the probability density) but let&amp;rsquo;s give it a go:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x1, x2 = np.mgrid[40:80:0.25, 40:80:0.25]
z = multivariate_normal(df.mean(), df.cov()).pdf(np.dstack((x1, x2)))
fig = go.Figure(data=[go.Surface(z=z)])
fig.update_xaxes(title_text=&#39;Heart Rate&#39;)
fig.update_yaxes(title_text=&#39;Probability Density&#39;)
fig.update_layout(width=700, height=700, title=&amp;quot;Multivariate Normal Heart Rate Distribution&amp;quot;,
                  scene = dict(xaxis = dict(title = &#39;9:05am&#39;),
                               yaxis = dict(title = &#39;9:00am&#39;),
                               zaxis = dict(title = &#39;Probability density&#39;)),
                  margin=dict(l=0, r=50, b=50, t=50))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;


&lt;div id=&#34;plotly_graph_2.json&#34; class=&#34;plotly&#34; style=&#34;height:700px&#34;&gt;&lt;/div&gt;
&lt;script&gt;
    Plotly.d3.json(&#34;plotly_graph_2.json&#34;, function (err, fig) {
        Plotly.plot(&#39;plotly_graph_2.json&#39;, fig.data, fig.layout, { responsive: true });
    });
&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Feel free to move the above plot around with your cursor. You can interpret the &amp;ldquo;height/elevation&amp;rdquo; in the plot as a probability, i.e., the higher the elevation, the more likely the values of heart rate at 9:00am/9:05am. In particular, note how if we observe a heart rate of 60 at 9:00am, the most probably value of your heart rate at 9:05am is about 62 or so. We can confirm that by looking at the cross-section of the above plot at 9:00am = 60:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = pd.DataFrame(z[80,:], index=x1[:,80]).plot(width=700, height=400, title=&amp;quot;Heart Rate at 9:05am given that Heart Rate at 9:00am = 60bpm&amp;quot;)
fig.update_xaxes(title_text=&#39;Heart Rate&#39;)
fig.update_yaxes(title_text=&#39;Probability Density&#39;)
fig.update_layout(xaxis = dict(range=[40, 80], tickmode = &#39;linear&#39;, dtick = 5),
                  showlegend=False)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;


&lt;div id=&#34;plotly_graph_3.json&#34; class=&#34;plotly&#34; style=&#34;height:400px&#34;&gt;&lt;/div&gt;
&lt;script&gt;
    Plotly.d3.json(&#34;plotly_graph_3.json&#34;, function (err, fig) {
        Plotly.plot(&#39;plotly_graph_3.json&#39;, fig.data, fig.layout, { responsive: true });
    });
&lt;/script&gt;&lt;/p&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;I hope this short post helped give some intuition about what multivariate distributions are and why they are useful. The example above is actually a bivariate distribution (two variables), but the intuition provided extends to more than two variables - it just gets harder to plot in more dimensions so I stuck to two variables here!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Party Planning with Probability</title>
      <link>https://www.tomasbeuzen.com/post/party-planning-probability/</link>
      <pubDate>Fri, 10 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://www.tomasbeuzen.com/post/party-planning-probability/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;My partner recently tasked me with coming up with the guest list for our wedding. Coming up with the list was easy - but how many people could we expect to actually attend? We needed a number to give to the various vendors catering our wedding so, as a bonafide nerd, I turned to probability and simulation for the answer. The idea was to assign a &amp;ldquo;probability of attendance&amp;rdquo; for each guest on my list, treat each guest&amp;rsquo;s attendance as a Bernoulli random variable, and run simulations to determine how many guests we might expect to attend the wedding.&lt;/p&gt;
&lt;p&gt;To this end, I whipped up a very simple Python package called 
&lt;a href=&#34;https://github.com/TomasBeuzen/pyguest&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pyguest&lt;/a&gt; which you can install with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ pip install pyguest
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;an-example&#34;&gt;An Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s walk through a quick example of how the package works. Below is the python code to create a hypothetical guest list, with each guest assigned a &amp;ldquo;probability of attending&amp;rdquo;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import math
import numpy as np
import pandas as pd
pd.options.plotting.backend = &amp;quot;plotly&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;np.random.seed(123)
guest = [f&amp;quot;Guest {i}&amp;quot; for i in range(1, 101)]
proba = np.random.randint(5, 11, 100) / 10
df = pd.DataFrame(proba, index=guest, columns=[&#39;Probability of Attending&#39;])
df.head(8)
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Probability of Attending&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Guest 1&lt;/th&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Guest 2&lt;/th&gt;
      &lt;td&gt;0.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Guest 3&lt;/th&gt;
      &lt;td&gt;0.9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Guest 4&lt;/th&gt;
      &lt;td&gt;0.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Guest 5&lt;/th&gt;
      &lt;td&gt;0.6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Guest 6&lt;/th&gt;
      &lt;td&gt;0.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Guest 7&lt;/th&gt;
      &lt;td&gt;0.7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Guest 8&lt;/th&gt;
      &lt;td&gt;0.8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;We can use 
&lt;a href=&#34;https://github.com/TomasBeuzen/pyguest&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pyguest&lt;/a&gt; to simulate wedding attendance from this guest list. The idea is to treat each guest&amp;rsquo;s attendance as a 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Bernoulli_distribution&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bernoulli random variable&lt;/a&gt;. For each simulation, we run through all the guests in the list and record how many &amp;ldquo;successes&amp;rdquo; we have (i.e, how many guests attend the wedding based on their respective probabilities). I&amp;rsquo;ve coded this up in pure NumPy and it&amp;rsquo;s nice and fast - ten thousand simulations can be run in literally the blink of an eye. Here&amp;rsquo;s the code to do it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pyguest import simulate

results = simulate(df[&#39;Probability of Attending&#39;], simulations=10000)
print(f&amp;quot;Results shape: {results.shape}&amp;quot;)
print(f&amp;quot;First 5 results: {results[:5]}&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Results shape: (10000,)
First 5 results: [69 78 73 78 78]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;results&lt;/code&gt; variable is an array containing the total number of attending guests in each of the 10,000 simulations. We can plot these results to help us understand how many of our 100 hypothetical guests will actually be attending the wedding.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = pd.DataFrame(results).plot.hist(histnorm=&#39;probability density&#39;, width=700, height=400)
fig.update_xaxes(title_text=&#39;Number of Guests&#39;)
fig.update_yaxes(title_text=&#39;Probability of Attending&#39;)
fig.update_layout(showlegend=False,
                  xaxis = dict(range=[57,90], tickmode = &#39;linear&#39;, tick0 = 55, dtick = 5))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;

&lt;script src=&#34;https://cdn.plot.ly/plotly-latest.min.js&#34;&gt;&lt;/script&gt;



&lt;div id=&#34;plotly_graph.json&#34; class=&#34;plotly&#34; style=&#34;height:400px&#34;&gt;&lt;/div&gt;
&lt;script&gt;
    Plotly.d3.json(&#34;plotly_graph.json&#34;, function (err, fig) {
        Plotly.plot(&#39;plotly_graph.json&#39;, fig.data, fig.layout, { responsive: true });
    });
&lt;/script&gt;&lt;/p&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;There you have it! We originally had a hypothetical guest list of 100 people, each with an allocated &amp;ldquo;probability of attendance&amp;rdquo;. After running 10,000 simulations, we get a distribution of expected guest attenendance and can use this distribution to inform our future planning - want to be conservative? Plan for 85 guests. Want to live a little riskier? You might be able to get away with planning for 75 guests. Obviously the simulation results depend on the probabilites you assign to each guest so use your best judgement!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unsupervised clustering with mixed categorical and continuous data</title>
      <link>https://www.tomasbeuzen.com/post/clustering-mixed-data/</link>
      <pubDate>Sun, 10 May 2020 00:00:00 +0000</pubDate>
      <guid>https://www.tomasbeuzen.com/post/clustering-mixed-data/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Recently I had to do some clustering of data that contained both continuous and categorical features. Standard clustering algorithms like k-means and DBSCAN don&amp;rsquo;t work with categorical data. After doing some research, I found that there wasn&amp;rsquo;t really a standard approach to the problem. So, I came up with a few different approaches, the practical implementations of which I&amp;rsquo;m documenting here and which I plan to come back to investigate further at some point:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Cluster using e.g., k-means or DBSCAN, based on only the continuous features;&lt;/li&gt;
&lt;li&gt;Numerically encode the categorical data before clustering with e.g., k-means or DBSCAN;&lt;/li&gt;
&lt;li&gt;Use k-prototypes to directly cluster the mixed data;&lt;/li&gt;
&lt;li&gt;Use FAMD (factor analysis of mixed data) to reduce the mixed data to a set of derived continuous features which can then be clustered.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I&amp;rsquo;ll describe each approach in a little more detail below, but first, if you plan to follow along, you&amp;rsquo;ll need to install the 
&lt;a href=&#34;https://github.com/kormilitzin/Prince&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;prince&lt;/a&gt; and 
&lt;a href=&#34;https://github.com/nicodv/kmodes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kmodes&lt;/a&gt; Python packages:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ pip install prince
$ pip install kmodes
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The post comes with a Jupyter notebook which you can find 
&lt;a href=&#34;https://github.com/TomasBeuzen/machine-learning-tutorials/blob/master/ml-clustering/clustering-mixed-data.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here on Github&lt;/a&gt;. Let&amp;rsquo;s get to our Python imports:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import pandas as pd
from prince import FAMD
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
from kmodes.kprototypes import KPrototypes
from sklearn.preprocessing import StandardScaler
random_state = 1234
pd.options.plotting.backend = &amp;quot;plotly&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also defined a custom plotting function to use in this post which leverages Pandas brand new 
&lt;a href=&#34;https://plotly.com/python/pandas-backend/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;plotly plotting backend&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def plot_cluster(X, y, title=&amp;quot;Cluster plot&amp;quot;):
    fig = X.plot.scatter(x=&#39;X1&#39;, y=&#39;X2&#39;, color=y)
    fig.update_layout(autosize=False, width=475, height=475,
                  coloraxis = dict(showscale=False, colorscale=&#39;Portland&#39;),
                  font=dict(size=18),
                  title=dict(text=title, x=0.5, y=0.95, xanchor=&#39;center&#39;))
    fig.update_traces(marker=dict(size=15))
    return fig
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, I&amp;rsquo;ll create some synthetic data to demonstrate the clustering methods discussed in this post. The data will have 50 observations, 3 features and 3 clusters. I standardise the numerical data with sklearn&amp;rsquo;s &lt;code&gt;StandardScaler()&lt;/code&gt; for clustering purposes (to make sure all features are on the same scale), and pretty arbitrarily convert one of the features to a categorical of &amp;ldquo;LOW&amp;rdquo; and &amp;ldquo;HIGH&amp;rdquo; values to demonstrate different approaches to clustering mixed data.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;X, y = make_blobs(n_samples=50, centers=3, n_features=3, random_state=random_state)
X = pd.DataFrame(X, columns=[&#39;X1&#39;, &#39;X2&#39;, &#39;X3&#39;])
X[&#39;X3&#39;] = np.where(X[&#39;X3&#39;] &amp;lt; 0, &#39;LOW&#39;, &#39;HIGH&#39;)
con_feats = [&#39;X1&#39;, &#39;X2&#39;] 
cat_feats = [&#39;X3&#39;]
scale = StandardScaler()
X[con_feats] = scale.fit_transform(X[con_feats])
X.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;X1&lt;/th&gt;
      &lt;th&gt;X2&lt;/th&gt;
      &lt;th&gt;X3&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;-0.495194&lt;/td&gt;
      &lt;td&gt;0.963114&lt;/td&gt;
      &lt;td&gt;HIGH&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;-0.548021&lt;/td&gt;
      &lt;td&gt;-1.762852&lt;/td&gt;
      &lt;td&gt;LOW&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;1.101047&lt;/td&gt;
      &lt;td&gt;0.935499&lt;/td&gt;
      &lt;td&gt;LOW&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;-0.694720&lt;/td&gt;
      &lt;td&gt;-1.779252&lt;/td&gt;
      &lt;td&gt;LOW&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1.261093&lt;/td&gt;
      &lt;td&gt;0.964404&lt;/td&gt;
      &lt;td&gt;LOW&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;Let&amp;rsquo;s plot our synthetic data (using our two continuous features as the &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; axes). There are 3 quite distinct blobs shown in blue, red, and yellow. However, there is a bit of mixture evident in the blue and red blobs and it will be interesting to explore how our different clustering approaches can capture this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = plot_cluster(X, y, title=&amp;quot;True Data&amp;quot;)
fig
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;

&lt;script src=&#34;https://cdn.plot.ly/plotly-latest.min.js&#34;&gt;&lt;/script&gt;



&lt;div id=&#34;plotly_graph_1.json&#34; class=&#34;plotly&#34; style=&#34;height:475px&#34;&gt;&lt;/div&gt;
&lt;script&gt;
    Plotly.d3.json(&#34;plotly_graph_1.json&#34;, function (err, fig) {
        Plotly.plot(&#39;plotly_graph_1.json&#39;, fig.data, fig.layout, { responsive: true });
    });
&lt;/script&gt;&lt;/p&gt;
&lt;h2 id=&#34;1-cluster-based-on-continuous-data-only&#34;&gt;1. Cluster based on continuous data only&lt;/h2&gt;
&lt;p&gt;The first question I asked myself when dealing with my mixed data was &amp;ldquo;Do I really need the information contained in the categorical features to extract patterns in my dataset?&amp;rdquo;. It could be that the continuous features available to you in your mixed data are adequate for grouping the data into representative clusters. So the first thing we&amp;rsquo;ll try here is to simply ignore our single categorical feature (which standard algorithms like k-means and DBSCAN don&amp;rsquo;t like), and only cluster based on our continuous features.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = KMeans(n_clusters=3, random_state=random_state).fit(X[con_feats])
pred = model.labels_
fig = plot_cluster(X, pred, title=&amp;quot;Continuous Only&amp;quot;)
fig
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;


&lt;div id=&#34;plotly_graph_2.json&#34; class=&#34;plotly&#34; style=&#34;height:475px&#34;&gt;&lt;/div&gt;
&lt;script&gt;
    Plotly.d3.json(&#34;plotly_graph_2.json&#34;, function (err, fig) {
        Plotly.plot(&#39;plotly_graph_2.json&#39;, fig.data, fig.layout, { responsive: true });
    });
&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are not too bad, we pick up the 3 main clusters, but do not identify that mixed data around (&lt;code&gt;X1=-1&lt;/code&gt;, &lt;code&gt;X2=0&lt;/code&gt;) evident in the true data (Figure 1).&lt;/p&gt;
&lt;h2 id=&#34;2-encode-the-categorical-data-before-clustering&#34;&gt;2. Encode the categorical data before clustering&lt;/h2&gt;
&lt;p&gt;Next we&amp;rsquo;ll try encoding the categorical data using one hot encoding so that we can include it in k-means clustering (note that you may also want to try scaling the data after OHE but I didn&amp;rsquo;t do that here for succinctness).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = KMeans(n_clusters=3, random_state=random_state).fit(pd.get_dummies(X))
pred = model.labels_
fig = plot_cluster(X, pred, title=&amp;quot;Encoded Categorical Data&amp;quot;)
fig
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;


&lt;div id=&#34;plotly_graph_3.json&#34; class=&#34;plotly&#34; style=&#34;height:475px&#34;&gt;&lt;/div&gt;
&lt;script&gt;
    Plotly.d3.json(&#34;plotly_graph_3.json&#34;, function (err, fig) {
        Plotly.plot(&#39;plotly_graph_3.json&#39;, fig.data, fig.layout, { responsive: true });
    });
&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are better than before, we get our 3 blobs, plus we identify some of that mixed data around (&lt;code&gt;X1=-1&lt;/code&gt;, &lt;code&gt;X2=0&lt;/code&gt;).&lt;/p&gt;
&lt;h2 id=&#34;3-use-the-k-prototypes-algorithm&#34;&gt;3. Use the k-prototypes algorithm&lt;/h2&gt;
&lt;p&gt;The k-prototypes algorithm can work directly with the categorical data, without the need for encoding. I defer to the 
&lt;a href=&#34;https://github.com/nicodv/kmodes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;k-prototypes documentation&lt;/a&gt; and the original paper by 
&lt;a href=&#34;https://grid.cs.gsu.edu/~wkim/index_files/papers/kprototype.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Huang (1997)&lt;/a&gt; for an explanation of how the algorithm works.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pred = KPrototypes(n_clusters=3).fit_predict(X, categorical=[2])
fig = plot_cluster(X, pred.astype(float), title=&amp;quot;k-prototypes&amp;quot;)
fig
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;


&lt;div id=&#34;plotly_graph_4.json&#34; class=&#34;plotly&#34; style=&#34;height:475px&#34;&gt;&lt;/div&gt;
&lt;script&gt;
    Plotly.d3.json(&#34;plotly_graph_4.json&#34;, function (err, fig) {
        Plotly.plot(&#39;plotly_graph_4.json&#39;, fig.data, fig.layout, { responsive: true });
    });
&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are similar to the above, we get our 3 blobs, plus we identify some of that mixed data around (&lt;code&gt;X1=-1&lt;/code&gt;, &lt;code&gt;X2=0&lt;/code&gt;).&lt;/p&gt;
&lt;h2 id=&#34;4-use-famd-to-create-continuous-features-for-clustering&#34;&gt;4. Use FAMD to create continuous features for clustering&lt;/h2&gt;
&lt;p&gt;Our final approach is to use FAMD (factor analysis for mixed data) to convert our mixed continuous and categorical data into derived continuous components (I chose 3 components here). I defer to the 
&lt;a href=&#34;https://github.com/kormilitzin/Prince&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prince documentation&lt;/a&gt; for an explanation of how the FAMD algorithm works.&lt;/p&gt;
&lt;p&gt;Here is an example of the 3 derived components for the first 5 observations in our synthetic dataset.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;famd = FAMD(n_components=3).fit(X)
famd.row_coordinates(X).head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;th&gt;2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;-0.134396&lt;/td&gt;
      &lt;td&gt;7.103708&lt;/td&gt;
      &lt;td&gt;-0.530751&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;7.067240&lt;/td&gt;
      &lt;td&gt;0.113685&lt;/td&gt;
      &lt;td&gt;1.561657&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;7.090335&lt;/td&gt;
      &lt;td&gt;0.082113&lt;/td&gt;
      &lt;td&gt;-1.083236&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;7.060651&lt;/td&gt;
      &lt;td&gt;0.122537&lt;/td&gt;
      &lt;td&gt;1.649692&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;7.097300&lt;/td&gt;
      &lt;td&gt;0.072753&lt;/td&gt;
      &lt;td&gt;-1.186533&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = KMeans(n_clusters=3, random_state=random_state).fit(famd.row_coordinates(X))
pred = model.labels_
fig = plot_cluster(X, pred, title=&amp;quot;FAMD + Clustering&amp;quot;)
fig
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;


&lt;div id=&#34;plotly_graph_5.json&#34; class=&#34;plotly&#34; style=&#34;height:475px&#34;&gt;&lt;/div&gt;
&lt;script&gt;
    Plotly.d3.json(&#34;plotly_graph_5.json&#34;, function (err, fig) {
        Plotly.plot(&#39;plotly_graph_5.json&#39;, fig.data, fig.layout, { responsive: true });
    });
&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are interesting here, we do get our 3 blobs but the bottom left blob is not very uniform. However, we perfectly identify the mixed labels around (&lt;code&gt;X1=-1&lt;/code&gt;, &lt;code&gt;X2=0&lt;/code&gt;), which no previous approach has been able to do.&lt;/p&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;In this post I documented a few approaches for clustering mixed continuous and categorical data. As always with data science, there is no one approach suited to all problems - in my opinion, clustering in particular is as much an art as a science. But, for the specific real-world application I was working on, I ended up going with approach number 4 (FAMD + clustering), because it yielded the best results for my dataset (which was significantly more complex than the one in this post, with ~400 mixed categorical and continuous features).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deploying machine learning models with Amazon SageMaker or Flask &amp; Heroku</title>
      <link>https://www.tomasbeuzen.com/post/deploy-ml-models/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://www.tomasbeuzen.com/post/deploy-ml-models/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I recently wrote up some 
&lt;a href=&#34;https://github.com/TomasBeuzen/machine-learning-tutorials/tree/master/ml-deploy-model&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tutorials on my GitHub&lt;/a&gt; to help data scientists deploy machine learning models. The aim of the tutorials is to provide a simple guide to deploying machine learning (ML) models for data scientists familiar with machine learning in a local environment, but interested in learning how to deploy their models. Deployment refers to the act of making your ML model available in a production environment, where it can be accessed and utilised by other software.&lt;/p&gt;
&lt;p&gt;Perhaps surprisingly, deployment is a process that is quite unfamiliar to many data scientists - in large part due to the need for some level of familiarity with software engineering. Fortunately, there are many tools avaialble to help us data scientists with deploying our models. The tutorials focus on currently and commonly used tools for ML deployment and are overwhelmingly practical, aiming to provide a useful overview of these tools and a foundation for using and expanding upon them in future. Here is a current list of tutorials, click a link to get started (to follow these tutorials, I recommend cloning the GitHub repository to your local machine):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/TomasBeuzen/machine-learning-tutorials/blob/master/ml-deploy-model/deploy-with-sagemaker.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Building and deploying a machine learning model with Amazon Sagemaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/TomasBeuzen/machine-learning-tutorials/blob/master/ml-deploy-model/deploy-with-flask.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deploying a machine learning model with Flask and Heroku&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Simultaneous feature preprocessing, feature selection, model selection, and hyperparameter tuning in scikit-learn with Pipeline and GridSearchCV</title>
      <link>https://www.tomasbeuzen.com/post/scikit-learn-gridsearch-pipelines/</link>
      <pubDate>Fri, 10 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://www.tomasbeuzen.com/post/scikit-learn-gridsearch-pipelines/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Some of the key steps in a machine learning workflow are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;feature preprocessing (encoding categorical features, scaling numeric features, transforming text data, etc.);&lt;/li&gt;
&lt;li&gt;feature selection (choosing which features to include in the model);&lt;/li&gt;
&lt;li&gt;model selection (choosing which machine learning estimator to use); and,&lt;/li&gt;
&lt;li&gt;hyperparameter tuning (determining the optimum hyperparameter values to use for each estimator).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It can be difficult to perform these tasks in an accurate, efficient and reproducible manner. In particular, it is important to ensure that, during cross-validation, feature preprocessing and feature selection are based only on the training portion of data, preventing leakage from the validation set which could bias our results. In this short, practical post I&amp;rsquo;ll demonstrate how to use 
&lt;a href=&#34;https://scikit-learn.org/stable/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;scikit-learn&lt;/a&gt; to simultaneously perform the above steps. While the example given is somewhat contrived, the syntax and workflow are what is important here and can be applied to any machine learning workflow.&lt;/p&gt;
&lt;h2 id=&#34;step-1-import-dependencies&#34;&gt;Step 1: Import dependencies&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.pipeline import Pipeline
from sklearn.datasets import make_classification
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectKBest, mutual_info_classif
pd.options.plotting.backend = &amp;quot;plotly&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;step-2-import-data&#34;&gt;Step 2: Import data&lt;/h2&gt;
&lt;p&gt;We will create a synthetic binary classification dataset for this demonstration using the scikit-learn function 
&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;make_classification&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;X, y = make_classification(n_samples=1000,
                           n_features=30,
                           n_informative=5,
                           n_redundant=5,
                           n_classes=2,
                           random_state=123)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The plot below shows 100 random points sampled from this synthetic dataset, with only the first two features used for plotting purposes.&lt;/p&gt;
&lt;p&gt;

&lt;script src=&#34;https://cdn.plot.ly/plotly-latest.min.js&#34;&gt;&lt;/script&gt;



&lt;div id=&#34;plotly_graph.json&#34; class=&#34;plotly&#34; style=&#34;height:500px&#34;&gt;&lt;/div&gt;
&lt;script&gt;
    Plotly.d3.json(&#34;plotly_graph.json&#34;, function (err, fig) {
        Plotly.plot(&#39;plotly_graph.json&#39;, fig.data, fig.layout, { responsive: true });
    });
&lt;/script&gt;&lt;/p&gt;
&lt;h2 id=&#34;step-3-create-pipeline-framework&#34;&gt;Step 3: Create pipeline framework&lt;/h2&gt;
&lt;p&gt;Using our synthetic dataset, we are going to set up a pipeline object that will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Standardize the data using 
&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;StandardScaler&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;Select the &lt;code&gt;k&lt;/code&gt; best features from the data using 
&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SelectKBest&lt;/a&gt; and the 
&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mutual information metric&lt;/a&gt; (where &lt;code&gt;k&lt;/code&gt; is a hyperparameter that we will tune during the fitting process); and,&lt;/li&gt;
&lt;li&gt;Use an estimator to model the data, here we will be trying a 
&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LogisticRegression&lt;/a&gt;, 
&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RandomForestClassifier&lt;/a&gt;, and 
&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;KNeighborsClassifier&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The syntax for creating this pipeline is shown below. To instantiate the &lt;code&gt;Pipeline&lt;/code&gt; object I&amp;rsquo;ve used  a &lt;code&gt;k&lt;/code&gt; value in &lt;code&gt;SelectKBest&lt;/code&gt; of 5 and I&amp;rsquo;ve input &lt;code&gt;LogisticRegression&lt;/code&gt; as the estimator, but these are simply placeholders for now and they will be varied during the fitting stage.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pipe = Pipeline([(&#39;scaler&#39;, StandardScaler()),
                 (&#39;selector&#39;, SelectKBest(mutual_info_classif, k=5)),
                 (&#39;classifier&#39;, LogisticRegression())])
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;step-4-create-search-space&#34;&gt;Step 4: Create search space&lt;/h2&gt;
&lt;p&gt;The next step is to define the space of hyperparameters and estimators we want to search through. We do this in the form of a dictionary and we use double underscore notation (&lt;code&gt;__&lt;/code&gt;) to refer to the hyperparameters of different steps in our pipeline. We will be trying out different values of &lt;code&gt;k&lt;/code&gt; for the feature selector &lt;code&gt;SelectKBest&lt;/code&gt;, as well as different hyperparameter values for each of our three estimators as shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;search_space = [{&#39;selector__k&#39;: [5, 10, 20, 30]},
                {&#39;classifier&#39;: [LogisticRegression(solver=&#39;lbfgs&#39;)],
                 &#39;classifier__C&#39;: [0.01, 0.1, 1.0]},
                {&#39;classifier&#39;: [RandomForestClassifier(n_estimators=100)],
                 &#39;classifier__max_depth&#39;: [5, 10, None]},
                {&#39;classifier&#39;: [KNeighborsClassifier()],
                 &#39;classifier__n_neighbors&#39;: [3, 7, 11],
                 &#39;classifier__weights&#39;: [&#39;uniform&#39;, &#39;distance&#39;]}]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;step-5-run-the-gridsearch&#34;&gt;Step 5: Run the GridSearch&lt;/h2&gt;
&lt;p&gt;This is where the magic happens. We will now pass our pipeline into 
&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GridSearchCV&lt;/a&gt; to test our search space (of feature preprocessing, feature selection, model selection, and hyperparameter tuning combinations) using 10-fold cross-validation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;clf = GridSearchCV(pipe, search_space, cv=10, verbose=0)
clf = clf.fit(X, y)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;step-6-get-the-results&#34;&gt;Step 6: Get the results&lt;/h2&gt;
&lt;p&gt;We can access the best result of our search using the &lt;code&gt;best_estimator_&lt;/code&gt; attribute. For this particular case, the &lt;code&gt;KNeighborsClassifier&lt;/code&gt; did the best, using &lt;code&gt;n_neighbors=3&lt;/code&gt; and &lt;code&gt;weights=&#39;distance&#39;&lt;/code&gt;, along with the &lt;code&gt;k=5&lt;/code&gt; best features chosen by &lt;code&gt;SelectKBest&lt;/code&gt;. This combination had a 10-fold cross-validation accuracy of 0.958.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;clf.best_estimator_
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Pipeline(memory=None,
         steps=[(&#39;scaler&#39;,
                 StandardScaler(copy=True, with_mean=True, with_std=True)),
                (&#39;selector&#39;,
                 SelectKBest(k=5,
                             score_func=&amp;lt;function mutual_info_classif at 0x15610c3b0&amp;gt;)),
                (&#39;classifier&#39;,
                 KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30,
                                      metric=&#39;minkowski&#39;, metric_params=None,
                                      n_jobs=None, n_neighbors=3, p=2,
                                      weights=&#39;distance&#39;))],
         verbose=False)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;clf.best_score_
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;0.958
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>The Git Fork-Branch-Pull Workflow</title>
      <link>https://www.tomasbeuzen.com/post/git-fork-branch-pull/</link>
      <pubDate>Fri, 25 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://www.tomasbeuzen.com/post/git-fork-branch-pull/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I primarily use Git and GitHub for my open-source work. However, if your anything like me, using these tools sometimes feels like a bit of a black box, nicely summarised by this xkcd comic:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image_2.png&#34; alt=&#34;png&#34;&gt;
&lt;strong&gt;&lt;em&gt;Git. Source: 
&lt;a href=&#34;https://xkcd.com/1597/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;xkcd.com&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I particularly feel this way when wanting to contribute to others&amp;rsquo; open-source projects on GitHub. For this, we typically use the &amp;ldquo;fork-and-branch&amp;rdquo; workflow. I wanted to document my simple approach to this workflow here (for reference by my future self and others). The workflow comprises the following steps which are described in more detail in the subsequent sections:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Fork a GitHub repository: navigate to a repository on GitHub and click the &lt;code&gt;Fork&lt;/code&gt; button.&lt;/li&gt;
&lt;li&gt;Clone the repository locally: &lt;code&gt;git clone https://github.com/user/repo.git&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Add remote called &amp;ldquo;upstream&amp;rdquo; pointing to the original repository: &lt;code&gt;git remote add upstream https://github.com/user/repo.git&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Checkout a new branch (here called &amp;ldquo;new_feature&amp;rdquo;): &lt;code&gt;git checkout -b new_feature&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Make desired changes to the local repository on this branch.&lt;/li&gt;
&lt;li&gt;Pull new changes from remote: &lt;code&gt;git checkout master&lt;/code&gt;, &lt;code&gt;git pull upstream master&lt;/code&gt;. Sync dev branch: &lt;code&gt;git checkout new_feature&lt;/code&gt;, &lt;code&gt;git merge master&lt;/code&gt;. Push changes to your remote repository: &lt;code&gt;git push origin new_feature&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Open a pull request on GitHub merging your changes with the upstream (original) repository.&lt;/li&gt;
&lt;li&gt;Once the pull request is accepted, you&amp;rsquo;ll want to pull those changes into your origin (forked repository). Change to master: &lt;code&gt;git checkout master&lt;/code&gt; and pull: &lt;code&gt;git pull upstream master&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Delete your feature branch using the GitHub website or, delete the local branch: &lt;code&gt;git branch -d new_feature&lt;/code&gt;, and delete the remote: &lt;code&gt;git push origin --delete new_feature&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;1-forking-a-github-repository&#34;&gt;1. Forking a GitHub Repository&lt;/h2&gt;
&lt;p&gt;The first step is to fork the GitHub repository you want to work on. A &amp;ldquo;fork&amp;rdquo; is just an independent copy of a repository that you can develop on without affecting the original. To fork a repository, find it on GitHub and then click the &lt;code&gt;Fork&lt;/code&gt; button.&lt;/p&gt;
&lt;h2 id=&#34;2-clone-the-repository-locally&#34;&gt;2. Clone the repository locally&lt;/h2&gt;
&lt;p&gt;Before you can make changes to the repository you&amp;rsquo;ll first want to make a local copy on your computer. This is as simple as using &lt;code&gt;git clone&lt;/code&gt; on the forked repository. Navigate to your forked repository on GitHub, click the &amp;ldquo;Clone or download&amp;rdquo; button and copy the url. Then, at the command line, clone the repository, for example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ git clone https://github.com/user/repo.git
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;3-add-a-remote&#34;&gt;3. Add a remote&lt;/h2&gt;
&lt;p&gt;When you cloned the forked repository onto your local computer, git automatically added a remote repository named &amp;ldquo;origin&amp;rdquo; pointing to the forked repository on GitHub. This means that when you do &lt;code&gt;git add&lt;/code&gt;/&lt;code&gt;git commit&lt;/code&gt;/&lt;code&gt;git push&lt;/code&gt; you can push your local changes to the forked repository.&lt;/p&gt;
&lt;p&gt;However, the goal here is to contribute to the original repository and we want to keep up to date with the original. While we are making changes, others might also be making changes and the original repository might be getting updated during the time you are adding a feature. So we want to add another remote pointing to the original repository so that we can periodically &lt;code&gt;git pull&lt;/code&gt; any changes that have occurred in that repository such that we are working on the must up-to-date version of the code. We usually call this remote &amp;ldquo;upstream&amp;rdquo; and can add it using:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ git remote add upstream https://github.com/user/repo.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can verify that you now have two remotes, &amp;ldquo;origin&amp;rdquo; and &amp;ldquo;upstream&amp;rdquo; using the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ git remote -v
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;4-checkout-a-new-branch&#34;&gt;4. Checkout a new branch&lt;/h2&gt;
&lt;p&gt;Okay, so now we&amp;rsquo;ve made a fork of the repository we want to work on, we&amp;rsquo;ve cloned it to our local computer and also added a remote pointing back to the original repository. Now we can start making our desired changes. To do this, we are going to want to create a branch to work on. This branch will be independent of the clean, functioning &amp;ldquo;master&amp;rdquo; code and is a safe place for you to delete, modify and add code. You can actually have multiple branches (for different features) that you&amp;rsquo;re working on at the same time. To create a branch called &amp;ldquo;new_feature&amp;rdquo;, use the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ git checkout -b new_feature
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can verify that you created the branch by using the following command which will show you all your local and remote branches:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ git branch -a
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;5-make-changes&#34;&gt;5. Make changes&lt;/h2&gt;
&lt;p&gt;Now that you have an independent workspace (a branch) to work on, that will not break any of the existing code, you can get to work implementing your changes. As you work you will &lt;code&gt;add&lt;/code&gt; and &lt;code&gt;commit&lt;/code&gt; changes you make. It is likely that the longer you take to implement your changes, the more changes could be made to the original &amp;ldquo;upstream&amp;rdquo; code - which could be problematic, especially if the code you are changing on your branch also gets changed in the upstream repository, which can leave you with a bunch of troublesome &amp;ldquo;merge conflicts&amp;rdquo; to deal with later on. If you want to make sure your branch stays up-to-date with the original repository you forked, you&amp;rsquo;ll need to do two things. Firstly, update your &amp;ldquo;master&amp;rdquo; fork of the original repository by checking out the master branch and pulling from the upstream repository:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ git checkout master
$ git pull upstream master
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, go back to your branch and merge it with the master to incorporate any new changes:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ git checkout new_feature
$ git merge master
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;6-push-changes&#34;&gt;6. Push changes&lt;/h2&gt;
&lt;p&gt;When you&amp;rsquo;ve made all the changes you want to make to the code you&amp;rsquo;ll want to push it to your remote &amp;ldquo;origin&amp;rdquo; to get it ready to show to the maintainers of the &amp;ldquo;upstream&amp;rdquo; (original) repository you wanted to contribute to in the first place. To do this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ git push origin new_feature
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will push your branch to your forked copy of the original repository.&lt;/p&gt;
&lt;h2 id=&#34;7-open-a-pull-request&#34;&gt;7. Open a pull request&lt;/h2&gt;
&lt;p&gt;Finally, we can open a &amp;ldquo;pull request&amp;rdquo; which essentially asks the maintainers of the original repository to take a look at and hopefully integrate your code changes into their repository. To open a pull request, go to the GitHub website, navigate to your &amp;ldquo;new_feature&amp;rdquo; branch and follow the prompts to open a pull request. Note that for many popular repositories, there will be a number of tasks you should complete before opening a pull request. For example, checking that the code still passes a number of pre-written tests, that the documentation still renders, etc. These kinds of guidelines for contributing to a repository are typically included in a repository&amp;rsquo;s root directory in a file called something like &amp;ldquo;contributing.md&amp;rdquo;.&lt;/p&gt;
&lt;h2 id=&#34;8-updating-your-fork&#34;&gt;8. Updating your fork&lt;/h2&gt;
&lt;p&gt;Once the maintainers accept your changes, the code you wrote will now be incorporated into the original repository. Hooray! Once this is done, you&amp;rsquo;ll want to update your fork of the original repository (because it now includes the changes you added through your branch and pull request workflow). Locally, we will make sure we are on the master branch, and we will pull changes from the upstream (original) repository:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ git checkout master
$ git pull upstream master
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;9-deleting-branches&#34;&gt;9. Deleting branches&lt;/h2&gt;
&lt;p&gt;Finally we can now delete our feature branch (both locally and remotely) because we no longer need it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ git branch -d new_feature
$ git push origin --delete new_feature
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that during the pull request workflow on GitHub, you may have already deleted your feature branch by following prompts on GitHub which is fine too.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building your own website with Hugo and GitHub Pages</title>
      <link>https://www.tomasbeuzen.com/post/making-a-website-with-hugo/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://www.tomasbeuzen.com/post/making-a-website-with-hugo/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I recently decided I wanted to create this personal website to serve as my online bio and to display various research and personal projects I am/have worked on. To my surprise, this actually turned out to be much easier than anticipated! So in this brief post I&amp;rsquo;ll walk you through how I created this website (for free!) in 5 simple steps using the static site generator 
&lt;a href=&#34;https://gohugo.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo&lt;/a&gt; and the static site hosting service provided by 
&lt;a href=&#34;https://pages.github.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub Pages&lt;/a&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;a href=&#34;#1&#34;&gt;Install Hugo and get a GitHub account&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#2&#34;&gt;Set up a workspace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#3&#34;&gt;Choose a theme for your website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#4&#34;&gt;Creating your website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#5&#34;&gt;Hosting your website on GitHub Pages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#6&#34;&gt;Updating your website&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;UPDATE 2020: The Academic Theme, which is one of the most popular Hugo website themes and the one I use in this post, now has 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;excellent documentation&lt;/a&gt; for setting up a website quickly and easily - check it out for up-to-date details on building a personal website with Hugo.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;step-1-install-hugo-and-get-a-github-account-a-name1a&#34;&gt;Step 1: Install Hugo and get a GitHub account &lt;a name=&#34;1&#34;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I&amp;rsquo;m a mac user, I&amp;rsquo;ll provide instructions here for installing Hugo on macOS. For instructions on installing Hugo on Windows or Linux, go to the 
&lt;a href=&#34;https://gohugo.io/getting-started/installing/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo Installation Page&lt;/a&gt; and then skip to Step 2. To install Hugo on macOS, you&amp;rsquo;ll ned both Homebrew and Go. Homebrew is a free and open-source software package management system that simplifies the installation of software on macOS and Go is a programming language created by Google that Hugo will leverage to create your website framework. If you don&amp;rsquo;t have Homebrew or Go installed on your computer, run the following in the terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ /usr/bin/ruby -e &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot;

$ brew install go
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, to install Hugo simply type:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ brew install hugo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, if you don&amp;rsquo;t already have a GitHub account, head over to the 
&lt;a href=&#34;https://github.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub website&lt;/a&gt; and create one.&lt;/p&gt;
&lt;h2 id=&#34;step-2-set-up-a-workspace-a-name2a&#34;&gt;Step 2: Set up a workspace &lt;a name=&#34;2&#34;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The next thing we need to do is create a directory from which we will build our website, this can be anywhere you like on your computer. You can create a directory using the macOS Finder or Windows File Explorer GUIs, or alternatively by using the command line. For example, the code below creates a new directory called &lt;strong&gt;&lt;em&gt;websites&lt;/em&gt;&lt;/strong&gt; in the &lt;strong&gt;&lt;em&gt;Documents&lt;/em&gt;&lt;/strong&gt; folder:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ cd ~/Documents

$ mkdir websites
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, from the command line, change into your new directory:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ cd websites
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this directory we will use Hugo to create the framework for your website. Simply type the following with &lt;strong&gt;&lt;em&gt;&amp;ldquo;websitename&amp;rdquo;&lt;/em&gt;&lt;/strong&gt; replaced with whatever you want to call your website:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ hugo new site websitename
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After executing this command, you will see something like the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Congratulations! Your new Hugo site is created in ~/Documents/websitename.

Just a few more steps and you are ready to go:

1. Download a theme into the same-named folder.
   Choose a theme from https://themes.gohugo.io/ or
   create your own with the &amp;quot;hugo new theme &amp;lt;THEMENAME&amp;gt;&amp;quot; command.
2. Perhaps you want to add some content. You can add single files
   with &amp;quot;hugo new &amp;lt;SECTIONNAME&amp;gt;/&amp;lt;FILENAME&amp;gt;.&amp;lt;FORMAT&amp;gt;&amp;quot;.
3. Start the built-in live server via &amp;quot;hugo server&amp;quot;.

Visit https://gohugo.io/ for quickstart guide and full documentation.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Change into your newly created  &lt;strong&gt;&lt;em&gt;websitename&lt;/em&gt;&lt;/strong&gt; directory and view the contents using &lt;code&gt;ls&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ cd websitename

$ ls

archetypes	content		layouts		themes
config.toml	data		static
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These files and folders form the framework of your Hugo site. We&amp;rsquo;ll explore them a little more later but for now, notice the &lt;strong&gt;&lt;em&gt;themes&lt;/em&gt;&lt;/strong&gt; folder. In the next step we will select a theme for your website and place it in this folder.&lt;/p&gt;
&lt;h2 id=&#34;step-3-choose-a-theme-for-your-website-a-name3a&#34;&gt;Step 3: Choose a theme for your website! &lt;a name=&#34;3&#34;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With Hugo you can create your very own website theme or download one of many different pre-made, open source themes. There are plenty of really great pre-made themes and they are perfect for getting your website up and running as quickly as possible. Head over to the 
&lt;a href=&#34;https://themes.gohugo.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo themes page&lt;/a&gt; and select a theme for your website. I used the 
&lt;a href=&#34;https://themes.gohugo.io/academic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic theme&lt;/a&gt; for my website.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image_2.png&#34; alt=&#34;png&#34;&gt;
&lt;strong&gt;&lt;em&gt;The gallery of themes available to build a website with Hugo.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once you&amp;rsquo;ve found a theme you like, click the &lt;strong&gt;&lt;em&gt;download&lt;/em&gt;&lt;/strong&gt; button which will take you to the theme&amp;rsquo;s GitHub repository. In the repository click the green &lt;strong&gt;&lt;em&gt;Clone or download&lt;/em&gt;&lt;/strong&gt; button and copy the https web URL. Go back to your terminal, &lt;code&gt;cd&lt;/code&gt; to the &lt;strong&gt;&lt;em&gt;themes&lt;/em&gt;&lt;/strong&gt; directory and clone the repository:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ cd themes

$ git clone https://github.com/gcushen/hugo-academic.git

archetypes	content		layouts		themes
config.toml	data		static
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can type &lt;code&gt;ls&lt;/code&gt; to see that you now have a directory called &lt;strong&gt;&lt;em&gt;hugo-academic&lt;/em&gt;&lt;/strong&gt; (or whatever other theme you chose). Now &lt;code&gt;cd&lt;/code&gt; into that directory and again type &lt;code&gt;ls&lt;/code&gt; to see the content of the directory; these are the files and folders you will need to create your website.&lt;/p&gt;
&lt;h2 id=&#34;step-4-creating-your-website-a-name4a&#34;&gt;Step 4: Creating your website &lt;a name=&#34;4&#34;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I found that the quickest (and dirtiest) way to get your website up and running is to simply copy everything in the folder &lt;strong&gt;&lt;em&gt;exampleSite&lt;/em&gt;&lt;/strong&gt; to your directory &lt;strong&gt;&lt;em&gt;websitename&lt;/em&gt;&lt;/strong&gt; - overwrite any duplications. Once you&amp;rsquo;ve done that, go ahead and copy all the other folders and files in &lt;strong&gt;&lt;em&gt;hugo-acaemic&lt;/em&gt;&lt;/strong&gt; (except for the &lt;strong&gt;&lt;em&gt;exampleSite&lt;/em&gt;&lt;/strong&gt; folder, &lt;strong&gt;&lt;em&gt;theme.toml&lt;/em&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;em&gt;README.md&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;LICENSE.md&lt;/em&gt;&lt;/strong&gt;) to your directory &lt;strong&gt;&lt;em&gt;websitename&lt;/em&gt;&lt;/strong&gt; - again, overwrite any duplications.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;image_3.png&#34; alt=&#34;png&#34;&gt;
&lt;strong&gt;&lt;em&gt;Example of what your directory might look like before and after copying the necessary files.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now you can see what your website currently looks like by changing to the directory &lt;strong&gt;&lt;em&gt;websitename&lt;/em&gt;&lt;/strong&gt; and typing:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ hugo server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This renders a local version of your website so you can see it and make changes before putting it online. Copy and paste the url output (e.g., &lt;strong&gt;&lt;em&gt;http://localhost:1313&lt;/em&gt;&lt;/strong&gt;) into your browser of choice to see your website.&lt;/p&gt;
&lt;p&gt;At this point go ahead and spend some time customizing your website. I recommend reading the documentation of the theme you chose to help navigate the folder and create new content. For example, 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; is the documentation for the academic theme. As you make changes, you should see that your website updates automatically in your browser - if for some reason it doesn&amp;rsquo;t, simply &lt;code&gt;ctrl+c&lt;/code&gt; in your terminal, re-execute &lt;code&gt;hugo server&lt;/code&gt;, and refresh your browser.&lt;/p&gt;
&lt;h3 id=&#34;step-5-hosting-your-website-on-github-pages-a-name5a&#34;&gt;Step 5: Hosting your website on GitHub Pages &lt;a name=&#34;5&#34;&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once you&amp;rsquo;re ready to show your shiny new website to the world, we can host it on GitHub Pages.&lt;/p&gt;
&lt;p&gt;The first thing you need to do is go to 
&lt;a href=&#34;https://github.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt; and create two empty repositories:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;a repository with the same name as the website directory you created: &amp;lsquo;websitename&amp;rsquo;; and,&lt;/li&gt;
&lt;li&gt;a repository with the name &amp;lsquo;yourgithubusername.github.io&amp;rsquo;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you haven&amp;rsquo;t created a repository before, simply click your GitHub profile at the top right-hand corner of the screen to see a drop-down menu, click &lt;strong&gt;&lt;em&gt;Your repositories&lt;/em&gt;&lt;/strong&gt; and on that page you will se a green button &lt;strong&gt;&lt;em&gt;New&lt;/em&gt;&lt;/strong&gt; which will help you create a repository. Once you&amp;rsquo;ve done that, copy the https key from the repository you created with the same name as your website and then in the terminal &lt;code&gt;cd&lt;/code&gt; to your local directory &lt;strong&gt;&lt;em&gt;websitename&lt;/em&gt;&lt;/strong&gt; and type:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt; $ git init

 $ git remote add origin https://github.com/User/websitename.git

 $ git push -u origin master
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will create a git directory, link it to the remote GitHub repository and then push the contents of the local directory to the remote. Note that the &lt;code&gt;-u&lt;/code&gt; argument specifies the master branch of the remote as &amp;ldquo;upstream&amp;rdquo;, meaning that in the future, a simple &lt;code&gt;git push&lt;/code&gt; will suffice when pushing changes to the remote.&lt;/p&gt;
&lt;p&gt;Now copy the https key from the repository you created with the name &lt;strong&gt;&lt;em&gt;yourgithubusername.github.io&lt;/em&gt;&lt;/strong&gt; and copy the https key. Then &lt;code&gt;cd&lt;/code&gt; back to your initial &lt;strong&gt;&lt;em&gt;websites&lt;/em&gt;&lt;/strong&gt; directory and type:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ git clone https://github.com/User/yourgithubusername.github.io.git # Clone the remote repo

$ cd websitename # Change directory

$ hugo -d ../yourgithubusername.github.io # Deploy your website

$ cd ../yourgithubusername.github.io

$ git add .

$ git commit -m &amp;quot;first commit&amp;quot;

$ git push -u origin master
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And that&amp;rsquo;s it! Go to GitHub and go to the repository &lt;strong&gt;&lt;em&gt;yourgithubusername.github.io&lt;/em&gt;&lt;/strong&gt;, click the settings tab near the top of the page and scroll down to the subheading &lt;strong&gt;&lt;em&gt;GitHub Pages&lt;/em&gt;&lt;/strong&gt; where you will see the link to your new website: &lt;code&gt;http://yourgitubusername.github.io&lt;/code&gt;. Click the link to see your website out in the wild. Congratulations - you can now show off your work to the world (wide web)!&lt;/p&gt;
&lt;h2 id=&#34;step-6-updating-your-website-a-name6a&#34;&gt;Step 6: Updating your website &lt;a name=&#34;6&#34;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;If you are going to have content on your website that will change over time (e.g., writing posts, updating research projects, changing your job title, etc.) then you&amp;rsquo;ll need to know how to make these changes to your website. Luckily, this is as easy as pie. Make any changes/additions to your website in your local directory &lt;strong&gt;&lt;em&gt;websitename&lt;/em&gt;&lt;/strong&gt; (remember to use &lt;code&gt;hugo server&lt;/code&gt; to render a local version of your website that you can view before deploying it online). Once you&amp;rsquo;ve made your changes make sure you&amp;rsquo;re in the &lt;strong&gt;&lt;em&gt;websitename&lt;/em&gt;&lt;/strong&gt; directory and type the following commands in terminal to push your local changes to the remote, re-deploy your website &lt;code&gt;yourgithubusername.github.io&lt;/code&gt; and then push that to the remote too:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ git add .

$ git commit -m &amp;quot;some changes&amp;quot;

$ git push # push all changes to the remote

$ hugo -d ../yourgithubusername.github.io # re-deploy website

$ cd ../yourgithubusername.github.io

$ git add .

$ git commit -m &amp;quot;some changes&amp;quot;

$ git push
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After this, you may need to wait ~10 minutes for the changes to take effect on the online version of your website.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
